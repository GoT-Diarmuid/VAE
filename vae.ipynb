{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "import os\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(imgs,names):\n",
    "  img_new = Image.new('L',(280,280))\n",
    "  index = 0\n",
    "  for i in range(0,280,80):\n",
    "    for j in range(0,280,80):\n",
    "      img = imgs[index]\n",
    "      img = Image.fromarray(img,mode='L')\n",
    "      img_new.paste(img,(i,j))\n",
    "      index+=1\n",
    "  img_new.save(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scale(x):\n",
    "  x = tf.cast(x,dtype=tf.float32)/255.\n",
    "#  y = tf.cast(y,dtype=tf.int32)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dim reduct nums\n",
    "dim_reduce = 10\n",
    "batch_num = 128\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28) (28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x,y),(x_test,y_test) = datasets.fashion_mnist.load_data()\n",
    "data = tf.data.Dataset.from_tensor_slices(x)\n",
    "data = data.map(feature_scale).shuffle(10000).batch(128)\n",
    "\n",
    "data_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "data_test = data_test.map(feature_scale).batch(128)\n",
    "\n",
    "data_iter = iter(data)\n",
    "samples = next(data_iter)\n",
    "print(samples[0].shape,samples[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "  def __init__(self):\n",
    "    super(VAE,self).__init__()\n",
    "    #encoder\n",
    "    self.fc_layer_1 = layers.Dense(128)\n",
    "    self.fc_layer_2 = layers.Dense(dim_reduce)\n",
    "    self.fc_layer_3 = layers.Dense(dim_reduce)\n",
    "    self.fc_layer_4 = layers.Dense(128)\n",
    "    self.fc_layer_5 = layers.Dense(784)\n",
    "    \n",
    "\n",
    "  def model_encoder(self, x):\n",
    "    h = tf.nn.relu(self.fc_layer_1(x))\n",
    "    mean_fc = self.fc_layer_2(h)\n",
    "    var_fc = self.fc_layer_3(h)\n",
    "    return mean_fc,var_fc\n",
    "\n",
    "  def model_decoder(self, z):\n",
    "    out = tf.nn.relu(self.fc_layer_4(z))\n",
    "    out = self.fc_layer_5(out)\n",
    "    return out\n",
    "\n",
    "  def reparameter(self,mean_x,var_x):\n",
    "    eps = tf.random.normal(var_x.shape)\n",
    "    std = tf.exp(var_x)**0.5\n",
    "    z = mean_x + std*eps\n",
    "    return z\n",
    "  \n",
    "  def call(self, inputs, training=None):\n",
    "    mean_x,var_x = self.model_encoder(inputs)\n",
    "    z = self.reparameter(mean_x,var_x)\n",
    "    x = self.model_decoder(z)\n",
    "    return x,mean_x,var_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  1290      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  1290      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  1408      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  101136    \n",
      "=================================================================\n",
      "Total params: 205,604\n",
      "Trainable params: 205,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VAE()\n",
    "model.build(input_shape=(4,784))\n",
    "optimizer = optimizers.Adam(lr=lr)\n",
    "model.summary()\n",
    "model.compile(optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' 不是內部或外部命令、可執行的程式或批次檔。\n"
     ]
    }
   ],
   "source": [
    "!rm -rf img_result\n",
    "!mkdir img_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 547.6412353515625 kl_div: 1.6040430068969727\n",
      "0 100 loss: 313.370361328125 kl_div: 14.808939933776855\n",
      "0 200 loss: 270.4798583984375 kl_div: 15.425350189208984\n",
      "0 300 loss: 271.3494873046875 kl_div: 14.688753128051758\n",
      "0 400 loss: 254.52890014648438 kl_div: 15.055817604064941\n",
      "1 0 loss: 268.33538818359375 kl_div: 13.637407302856445\n",
      "1 100 loss: 261.97802734375 kl_div: 13.590749740600586\n",
      "1 200 loss: 258.56719970703125 kl_div: 14.495540618896484\n",
      "1 300 loss: 257.16766357421875 kl_div: 14.42913818359375\n",
      "1 400 loss: 256.2521667480469 kl_div: 14.208840370178223\n",
      "2 0 loss: 253.90521240234375 kl_div: 14.05722713470459\n",
      "2 100 loss: 262.0010986328125 kl_div: 14.271929740905762\n",
      "2 200 loss: 246.49794006347656 kl_div: 13.743783950805664\n",
      "2 300 loss: 262.81915283203125 kl_div: 14.200222969055176\n",
      "2 400 loss: 259.02520751953125 kl_div: 14.237686157226562\n",
      "3 0 loss: 255.36782836914062 kl_div: 14.131688117980957\n",
      "3 100 loss: 250.78656005859375 kl_div: 14.587200164794922\n",
      "3 200 loss: 249.3467254638672 kl_div: 14.191694259643555\n",
      "3 300 loss: 254.1759033203125 kl_div: 14.539901733398438\n",
      "3 400 loss: 260.406982421875 kl_div: 14.972555160522461\n",
      "4 0 loss: 248.86354064941406 kl_div: 14.736529350280762\n",
      "4 100 loss: 246.0029296875 kl_div: 14.525798797607422\n",
      "4 200 loss: 249.59664916992188 kl_div: 14.981600761413574\n",
      "4 300 loss: 259.1224365234375 kl_div: 13.898473739624023\n",
      "4 400 loss: 247.38246154785156 kl_div: 14.231019020080566\n",
      "5 0 loss: 254.83998107910156 kl_div: 14.773563385009766\n",
      "5 100 loss: 241.36773681640625 kl_div: 14.461051940917969\n",
      "5 200 loss: 250.0247039794922 kl_div: 15.079636573791504\n",
      "5 300 loss: 248.84214782714844 kl_div: 15.193741798400879\n",
      "5 400 loss: 259.2254943847656 kl_div: 14.626300811767578\n",
      "6 0 loss: 243.8922882080078 kl_div: 14.581730842590332\n",
      "6 100 loss: 249.51097106933594 kl_div: 15.05792236328125\n",
      "6 200 loss: 250.9659423828125 kl_div: 14.49459171295166\n",
      "6 300 loss: 248.77349853515625 kl_div: 13.902652740478516\n",
      "6 400 loss: 248.17657470703125 kl_div: 15.265507698059082\n",
      "7 0 loss: 261.9732360839844 kl_div: 14.528061866760254\n",
      "7 100 loss: 251.24417114257812 kl_div: 14.776883125305176\n",
      "7 200 loss: 249.8723602294922 kl_div: 14.50983715057373\n",
      "7 300 loss: 247.24392700195312 kl_div: 14.538131713867188\n",
      "7 400 loss: 254.7242431640625 kl_div: 14.311649322509766\n",
      "8 0 loss: 243.3865203857422 kl_div: 14.626471519470215\n",
      "8 100 loss: 249.1050567626953 kl_div: 14.00816822052002\n",
      "8 200 loss: 245.42489624023438 kl_div: 14.165010452270508\n",
      "8 300 loss: 240.88604736328125 kl_div: 14.815837860107422\n",
      "8 400 loss: 254.33935546875 kl_div: 14.40502643585205\n",
      "9 0 loss: 238.52662658691406 kl_div: 15.06657886505127\n",
      "9 100 loss: 258.0828857421875 kl_div: 14.172224044799805\n",
      "9 200 loss: 239.03326416015625 kl_div: 14.816427230834961\n",
      "9 300 loss: 240.23660278320312 kl_div: 14.643750190734863\n",
      "9 400 loss: 248.74815368652344 kl_div: 15.241650581359863\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(lr=lr)\n",
    "for i in range(10):\n",
    "  for step,x in enumerate(data):\n",
    "    x = tf.reshape(x,[-1,784])\n",
    "    with tf.GradientTape() as tape:\n",
    "      logits,mean_x,var_x = model(x)\n",
    "      loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x,logits=logits)\n",
    "      loss = tf.reduce_sum(loss)/x.shape[0]\n",
    "      kl_div = -0.5*(var_x+1-mean_x**2-tf.exp(var_x))\n",
    "      kl_div = tf.reduce_sum(kl_div)/x.shape[0]\n",
    "      \n",
    "      loss = loss + 1.*kl_div\n",
    "    grads = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    \n",
    "    if step %100==0:\n",
    "      print(i,step,'loss:',float(loss),'kl_div:',float(kl_div))\n",
    "      \n",
    "  x = next(iter(data_test))\n",
    "  val_x = tf.reshape(x,[-1,784])\n",
    "  logits,_,_ = model(val_x)\n",
    "  x_hat = tf.sigmoid(logits)\n",
    "  x_hat = tf.reshape(x_hat,[-1,28,28])\n",
    "  x_hat = x_hat.numpy()*255\n",
    "  x_hat = x_hat.astype(np.uint8)\n",
    "  save_img(x_hat,'img_result/AE_img_%d.png'%i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}